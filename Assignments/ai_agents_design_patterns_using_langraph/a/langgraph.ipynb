{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V28","authorship_tag":"ABX9TyNQl3YnxfkhGZE3hWaNHgzI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"V5e5kL74DZBm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746215890039,"user_tz":420,"elapsed":6466,"user":{"displayName":"Aditya Rajpurohit","userId":"09650524129068723281"}},"outputId":"25ffabfc-965f-4a4b-f0e1-d8c925f6f7fc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.76.0)\n","Collecting openai\n","  Downloading openai-1.77.0-py3-none-any.whl.metadata (25 kB)\n","Collecting langchain-openai\n","  Downloading langchain_openai-0.3.16-py3-none-any.whl.metadata (2.3 kB)\n","Collecting langgraph\n","  Downloading langgraph-0.4.1-py3-none-any.whl.metadata (7.9 kB)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.3)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n","Collecting langchain-core<1.0.0,>=0.3.58 (from langchain-openai)\n","  Downloading langchain_core-0.3.58-py3-none-any.whl.metadata (5.9 kB)\n","Collecting tiktoken<1,>=0.7 (from langchain-openai)\n","  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n","  Downloading langgraph_checkpoint-2.0.25-py3-none-any.whl.metadata (4.6 kB)\n","Collecting langgraph-prebuilt>=0.1.8 (from langgraph)\n","  Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl.metadata (5.0 kB)\n","Collecting langgraph-sdk>=0.1.42 (from langgraph)\n","  Downloading langgraph_sdk-0.1.66-py3-none-any.whl.metadata (1.8 kB)\n","Collecting xxhash<4.0.0,>=3.5.0 (from langgraph)\n","  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n","Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain-openai) (0.3.38)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain-openai) (9.1.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain-openai) (1.33)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain-openai) (6.0.2)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain-openai) (24.2)\n","Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph)\n","  Downloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.17)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain-openai) (3.0.0)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.58->langchain-openai) (1.0.0)\n","Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.58->langchain-openai) (0.23.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.1)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.4.0)\n","Downloading openai-1.77.0-py3-none-any.whl (662 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m662.0/662.0 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_openai-0.3.16-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langgraph-0.4.1-py3-none-any.whl (151 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.2/151.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_core-0.3.58-py3-none-any.whl (437 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.6/437.6 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langgraph_checkpoint-2.0.25-py3-none-any.whl (42 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langgraph_prebuilt-0.1.8-py3-none-any.whl (25 kB)\n","Downloading langgraph_sdk-0.1.66-py3-none-any.whl (47 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, ormsgpack, tiktoken, openai, langgraph-sdk, langchain-core, langgraph-checkpoint, langchain-openai, langgraph-prebuilt, langgraph\n","  Attempting uninstall: openai\n","    Found existing installation: openai 1.76.0\n","    Uninstalling openai-1.76.0:\n","      Successfully uninstalled openai-1.76.0\n","  Attempting uninstall: langchain-core\n","    Found existing installation: langchain-core 0.3.56\n","    Uninstalling langchain-core-0.3.56:\n","      Successfully uninstalled langchain-core-0.3.56\n","Successfully installed langchain-core-0.3.58 langchain-openai-0.3.16 langgraph-0.4.1 langgraph-checkpoint-2.0.25 langgraph-prebuilt-0.1.8 langgraph-sdk-0.1.66 openai-1.77.0 ormsgpack-1.9.1 tiktoken-0.9.0 xxhash-3.5.0\n"]}],"source":["# install\n","!pip install --upgrade openai langchain-openai langgraph"]},{"cell_type":"code","source":["import os\n","from langchain_openai import ChatOpenAI\n","\n","os.environ[\"OPENAI_API_KEY\"] = \"\"\n","os.environ[\"LANGCHAIN_API_KEY\"] = \"\"\n","os.environ[\"LANGCHAIN_PROJECT\"] = \"\"\n","\n","llm_base = ChatOpenAI(model=\"gpt-4\", temperature=0.7)"],"metadata":{"id":"0nf-iMN0Sn51","executionInfo":{"status":"ok","timestamp":1746216126014,"user_tz":420,"elapsed":52,"user":{"displayName":"Aditya Rajpurohit","userId":"09650524129068723281"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# Structured Output with Pydantic"],"metadata":{"id":"CO0SwYJ5S_cb"}},{"cell_type":"code","source":["from pydantic import BaseModel, Field\n","\n","class SearchTask(BaseModel):\n","    reformulated: str = Field(..., description=\"Optimized query for web search\")\n","    rationale: str = Field(..., description=\"Why this query is effective\")\n","\n","structured_llm = llm_base.with_structured_output(SearchTask)\n","structured_out = structured_llm.invoke(\"What's the connection between gut health and mental health?\")\n","print(\"Structured Output:\\n\", structured_out)"],"metadata":{"id":"6vXbWc0DSn8r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Tool Binding"],"metadata":{"id":"xLjeJqA-TDTt"}},{"cell_type":"code","source":["from langchain_core.tools import tool\n","\n","@tool\n","def multiply(x: int, y: int) -> int:\n","    return x * y\n","\n","@tool\n","def add(x: int, y: int) -> int:\n","    return x + y\n","\n","@tool\n","def divide(x: int, y: int) -> float:\n","    return x / y\n","\n","math_tools = [multiply, add, divide]\n","llm_with_math = llm_base.bind_tools(math_tools)\n","\n","response = llm_with_math.invoke(\"What's 15 divided by 3?\")\n","print(\"Tool Call Output:\\n\", response.tool_calls)"],"metadata":{"id":"utEUak9WSn_X","executionInfo":{"status":"aborted","timestamp":1746215891591,"user_tz":420,"elapsed":8165,"user":{"displayName":"Aditya Rajpurohit","userId":"09650524129068723281"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Prompt Chaining"],"metadata":{"id":"6QxGbVIkV41b"}},{"cell_type":"code","source":["from typing_extensions import TypedDict\n","from langgraph.graph import StateGraph, START, END\n","\n","class JokeState(TypedDict):\n","    topic: str\n","    raw_joke: str\n","    upgraded_joke: str\n","    final_joke: str\n","\n","def make_joke(state: JokeState):\n","    return {\"raw_joke\": llm_base.invoke(f\"Tell a joke about {state['topic']}\").content}\n","\n","def has_punchline(state: JokeState):\n","    return \"good\" if \"!\" in state[\"raw_joke\"] or \"?\" in state[\"raw_joke\"] else \"edit\"\n","\n","def improve_joke(state: JokeState):\n","    return {\"upgraded_joke\": llm_base.invoke(f\"Improve this joke: {state['raw_joke']}\").content}\n","\n","def polish_joke(state: JokeState):\n","    return {\"final_joke\": llm_base.invoke(f\"Add a twist: {state['upgraded_joke']}\").content}"],"metadata":{"id":"2-EkxqHeSoBv","executionInfo":{"status":"aborted","timestamp":1746215891607,"user_tz":420,"elapsed":8177,"user":{"displayName":"Aditya Rajpurohit","userId":"09650524129068723281"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["joke_graph = StateGraph(JokeState)\n","joke_graph.add_node(\"make_joke\", make_joke)\n","joke_graph.add_node(\"improve_joke\", improve_joke)\n","joke_graph.add_node(\"polish_joke\", polish_joke)\n","joke_graph.add_edge(START, \"make_joke\")\n","joke_graph.add_conditional_edges(\"make_joke\", has_punchline, {\"good\": END, \"edit\": \"improve_joke\"})\n","joke_graph.add_edge(\"improve_joke\", \"polish_joke\")\n","joke_graph.add_edge(\"polish_joke\", END)\n","joke_chain = joke_graph.compile()\n","\n","result = joke_chain.invoke({\"topic\": \"aliens\"})\n","print(\"Final Joke Flow Result:\\n\", result)"],"metadata":{"id":"GSETXOceV-zp","executionInfo":{"status":"aborted","timestamp":1746215891611,"user_tz":420,"elapsed":8176,"user":{"displayName":"Aditya Rajpurohit","userId":"09650524129068723281"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Parallel Graph"],"metadata":{"id":"R6oar1izTS7T"}},{"cell_type":"code","source":["class CreativeState(TypedDict):\n","    theme: str\n","    story: str\n","    haiku: str\n","    tweet: str\n","    combined: str\n","\n","def gen_story(s): return {\"story\": llm_base.invoke(f\"Write a short story about {s['theme']}\").content}\n","def gen_haiku(s): return {\"haiku\": llm_base.invoke(f\"Haiku on {s['theme']}\").content}\n","def gen_tweet(s): return {\"tweet\": llm_base.invoke(f\"Tweet about {s['theme']}\").content}\n","\n","def merge_outputs(s):\n","    return {\n","        \"combined\": f\"📝 Story: {s['story'][:80]}...\\n🌸 Haiku: {s['haiku']}\\n🐦 Tweet: {s['tweet']}\"\n","    }"],"metadata":{"id":"J2pWeOANSoEV","executionInfo":{"status":"aborted","timestamp":1746215891632,"user_tz":420,"elapsed":1,"user":{"displayName":"Aditya Rajpurohit","userId":"09650524129068723281"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["parallel = StateGraph(CreativeState)\n","parallel.add_node(\"gen_story\", gen_story)\n","parallel.add_node(\"gen_haiku\", gen_haiku)\n","parallel.add_node(\"gen_tweet\", gen_tweet)\n","parallel.add_node(\"merge\", merge_outputs)\n","\n","parallel.add_edge(START, \"gen_story\")\n","parallel.add_edge(START, \"gen_haiku\")\n","parallel.add_edge(START, \"gen_tweet\")\n","parallel.add_edge(\"gen_story\", \"merge\")\n","parallel.add_edge(\"gen_haiku\", \"merge\")\n","parallel.add_edge(\"gen_tweet\", \"merge\")\n","parallel.add_edge(\"merge\", END)\n","\n","creative_chain = parallel.compile()\n","out = creative_chain.invoke({\"theme\": \"ocean\"})\n","print(\"Creative Fusion Output:\\n\", out[\"combined\"])"],"metadata":{"id":"ICBLsxibSoHJ","executionInfo":{"status":"aborted","timestamp":1746215891648,"user_tz":420,"elapsed":13,"user":{"displayName":"Aditya Rajpurohit","userId":"09650524129068723281"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dynamic Router"],"metadata":{"id":"KP2fp8ChTbVh"}},{"cell_type":"code","source":["from typing import Literal\n","class Selector(BaseModel):\n","    route: Literal[\"story\", \"poem\", \"joke\"] = Field(...)\n","\n","router_llm = llm_base.with_structured_output(Selector)\n","\n","class RouteState(TypedDict):\n","    input: str\n","    route: str\n","    result: str\n","\n","def choose_route(s: RouteState):\n","    d = router_llm.invoke(f\"Classify this: {s['input']}\")\n","    return {\"route\": d.route}\n","\n","def do_story(s): return {\"result\": llm_base.invoke(f\"Story: {s['input']}\").content}\n","def do_poem(s): return {\"result\": llm_base.invoke(f\"Poem: {s['input']}\").content}\n","def do_joke(s): return {\"result\": llm_base.invoke(f\"Joke: {s['input']}\").content}\n","\n","def routing_logic(s: RouteState):\n","    return {\"story\": \"do_story\", \"poem\": \"do_poem\", \"joke\": \"do_joke\"}[s[\"route\"]]"],"metadata":{"id":"jEZdeqJ3TcOl","executionInfo":{"status":"aborted","timestamp":1746215891650,"user_tz":420,"elapsed":4,"user":{"displayName":"Aditya Rajpurohit","userId":"09650524129068723281"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["route_graph = StateGraph(RouteState)\n","route_graph.add_node(\"choose_route\", choose_route)\n","route_graph.add_node(\"do_story\", do_story)\n","route_graph.add_node(\"do_poem\", do_poem)\n","route_graph.add_node(\"do_joke\", do_joke)\n","\n","route_graph.add_edge(START, \"choose_route\")\n","route_graph.add_conditional_edges(\"choose_route\", routing_logic,\n","    {\"do_story\": \"do_story\", \"do_poem\": \"do_poem\", \"do_joke\": \"do_joke\"})\n","route_graph.add_edge(\"do_story\", END)\n","route_graph.add_edge(\"do_poem\", END)\n","route_graph.add_edge(\"do_joke\", END)\n","\n","compiled_route = route_graph.compile()\n","out = compiled_route.invoke({\"input\": \"Write me a short poem about dawn\"})\n","print(\"Routing Output:\\n\", out[\"result\"])"],"metadata":{"id":"utSDf3X_WRmy","executionInfo":{"status":"aborted","timestamp":1746215891651,"user_tz":420,"elapsed":4,"user":{"displayName":"Aditya Rajpurohit","userId":"09650524129068723281"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Evaluator-Optimizer Loop"],"metadata":{"id":"HdmHa5xmWU6u"}},{"cell_type":"code","source":["class Review(BaseModel):\n","    verdict: Literal[\"funny\", \"not funny\"]\n","    comments: str\n","\n","from typing_extensions import Annotated\n","import operator\n","\n","class FunnyState(TypedDict):\n","    topic: str\n","    joke: str\n","    verdict: str\n","    comments: str\n","\n","eval_llm = llm_base.with_structured_output(Review)"],"metadata":{"id":"A1xmSeIJWbQC","executionInfo":{"status":"aborted","timestamp":1746215891672,"user_tz":420,"elapsed":8207,"user":{"displayName":"Aditya Rajpurohit","userId":"09650524129068723281"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_funny(s: FunnyState):\n","    if s.get(\"comments\"):\n","        return {\"joke\": llm_base.invoke(f\"Joke about {s['topic']} with feedback: {s['comments']}\").content}\n","    return {\"joke\": llm_base.invoke(f\"Joke about {s['topic']}\").content}\n","\n","def evaluate_funny(s: FunnyState):\n","    result = eval_llm.invoke(s[\"joke\"])\n","    return {\"verdict\": result.verdict, \"comments\": result.comments}\n","\n","def route_funny(s: FunnyState):\n","    return \"pass\" if s[\"verdict\"] == \"funny\" else \"retry\""],"metadata":{"id":"O4wDDdqVWfcQ","executionInfo":{"status":"aborted","timestamp":1746215891674,"user_tz":420,"elapsed":8200,"user":{"displayName":"Aditya Rajpurohit","userId":"09650524129068723281"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loop = StateGraph(FunnyState)\n","loop.add_node(\"generate\", generate_funny)\n","loop.add_node(\"evaluate\", evaluate_funny)\n","loop.add_edge(START, \"generate\")\n","loop.add_edge(\"generate\", \"evaluate\")\n","loop.add_conditional_edges(\"evaluate\", route_funny, {\"pass\": END, \"retry\": \"generate\"})\n","funny_chain = loop.compile()\n","\n","out = funny_chain.invoke({\"topic\": \"coffee\"})\n","print(\"Final Joke:\\n\", out[\"joke\"])"],"metadata":{"id":"EQRgMTXVWfez","executionInfo":{"status":"aborted","timestamp":1746215891675,"user_tz":420,"elapsed":8194,"user":{"displayName":"Aditya Rajpurohit","userId":"09650524129068723281"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Agent with Tool"],"metadata":{"id":"VMeOvm0DWir6"}},{"cell_type":"code","source":["from langgraph.graph import MessagesState\n","from langchain_core.messages import SystemMessage, HumanMessage, ToolMessage\n","\n","tools_map = {t.name: t for t in math_tools}\n","llm_agent = llm_base.bind_tools(math_tools)\n","\n","def agent_call(state: MessagesState):\n","    msg = llm_agent.invoke([SystemMessage(content=\"You are a math helper.\")] + state[\"messages\"])\n","    return {\"messages\": [msg]}\n","\n","def run_tool(state: MessagesState):\n","    outputs = []\n","    for call in state[\"messages\"][-1].tool_calls:\n","        fn = tools_map[call[\"name\"]]\n","        result = fn.invoke(call[\"args\"])\n","        outputs.append(ToolMessage(content=result, tool_call_id=call[\"id\"]))\n","    return {\"messages\": outputs}\n","\n","def should_continue(state: MessagesState):\n","    return \"tool\" if state[\"messages\"][-1].tool_calls else END"],"metadata":{"id":"Lf9nAOvcWiz7","executionInfo":{"status":"aborted","timestamp":1746215891676,"user_tz":420,"elapsed":8191,"user":{"displayName":"Aditya Rajpurohit","userId":"09650524129068723281"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["agent_graph = StateGraph(MessagesState)\n","agent_graph.add_node(\"agent_call\", agent_call)\n","agent_graph.add_node(\"tool\", run_tool)\n","agent_graph.add_edge(START, \"agent_call\")\n","agent_graph.add_conditional_edges(\"agent_call\", should_continue, {\"tool\": \"tool\", END: END})\n","agent_graph.add_edge(\"tool\", \"agent_call\")\n","agent_final = agent_graph.compile()\n","\n","messages = agent_final.invoke({\"messages\": [HumanMessage(content=\"What is 8 * 7?\")]})\n","for msg in messages[\"messages\"]:\n","    msg.pretty_print()"],"metadata":{"id":"JYpYb25UWqd4","executionInfo":{"status":"aborted","timestamp":1746215891699,"user_tz":420,"elapsed":8209,"user":{"displayName":"Aditya Rajpurohit","userId":"09650524129068723281"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# LangSmith Trace Example"],"metadata":{"id":"Xn1YCA4sWq-j"}},{"cell_type":"code","source":["from langsmith import traceable\n","\n","@traceable(run_type=\"llm\")\n","def explain_topic(topic: str):\n","    return llm_base.invoke(f\"Explain {topic} in simple terms.\").content\n","\n","print(\"LangSmith Trace:\\n\", explain_topic(\"blockchain\"))"],"metadata":{"id":"k0Wj-t72Ws9c","executionInfo":{"status":"aborted","timestamp":1746215891701,"user_tz":420,"elapsed":8208,"user":{"displayName":"Aditya Rajpurohit","userId":"09650524129068723281"}}},"execution_count":null,"outputs":[]}]}