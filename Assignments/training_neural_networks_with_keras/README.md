# Training Neural Networks with Keras Advanced

## Overview

This project demonstrates various techniques in **deep learning generalization**, **data augmentation**, and **model customization** using **TensorFlow/Keras**. It is structured into two major parts:

1. **Data Augmentation & Regularization** — focuses on improving generalization through augmentation and regularization strategies.
2. **Advanced Keras Constructs** — explores customization of training loops, layers, losses, and optimizers for maximum flexibility.

---

- [Part 1: Augmentation & Regularization](#-part-1-augmentation--regularization)
- [Part 2: Advanced Keras Customization](#-part-2-advanced-keras-customization)

---

[Video Demo](https://youtu.be/DtWkxSqxBO4)

---

**Colabs included:**

| Notebook | Description |
|---------|-------------|
| `01_l1_l2_regularization.ipynb` | Add weight penalties to reduce overfitting |
| `02_dropout_and_batchnorm.ipynb` | Compare Dropout vs BatchNorm |
| `03_early_stopping_and_tensorboard.ipynb` | Use callbacks to stop early and visualize training |
| `04_keras_cv_augmentations.ipynb` | Image augmentation with KerasCV |
| `05_nlp_timeseries_speech_aug.ipynb` | Augmentations for text, speech, time series |
| `06_keras_tuner_example.ipynb` | Auto-tuning hyperparameters with KerasTuner |
| `07_fastai_augmentations.ipynb` | Demonstrate FastAI's image augmentation |
| `08_custom_regularizer_dropout.ipynb` | Implement custom dropout and regularizers |
| `09_custom_lr_scheduler.ipynb` | One-cycle scheduler implementation |
| `10_custom_layers_and_constraints.ipynb` | Custom dense layer with constraints |
| `11_custom_loss_metric_activation.ipynb` | Huber loss, custom metrics, leaky relu |
| `12_custom_model_resnet.ipynb` | Residual block and custom model class |
| `13_custom_training_loop.ipynb` | Full manual training using GradientTape |
| `14_tensorboard_debugging.ipynb` | Visualizations using TensorBoard |

Each notebook includes A/B tests between regularized and unregularized models.


Link to Colab - [k_data_augmentation](https://colab.research.google.com/drive/1N7wX2fbhp7BrSwhsK6r-xovoePZ17ihg?usp=sharing)